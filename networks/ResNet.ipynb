{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import itertools\n",
    "\n",
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_ResNet50(number_classes, input_shape=(224,224,3),optimizer, metrics):\n",
    "    base_model = keras.applications.ResNet50(\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        include_top=False)\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(number_classes)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_ResNet101(number_classes, input_shape=(224,224,3),optimizer, metrics):\n",
    "    base_model = keras.applications.ResNet101(\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        include_top=False)\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(number_classes)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_ResNet152(number_classes, input_shape=(224,224,3),optimizer, metrics):\n",
    "    base_model = keras.applications.ResNet152(\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        include_top=False)\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(number_classes)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONSTANTS\n",
    "in_shape = (224, 224, 3)\n",
    "INPUT_SIZE = 224\n",
    "\n",
    "train_dir = './cats/v4/train'\n",
    "test_dir = './cats/v4/test'\n",
    "breeds = os.listdir(train_dir)\n",
    "no_classes = len(breeds)\n",
    "no_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10, mode='min', min_delta=0.01, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax()\n",
    "metrics=[keras.metrics.CategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs=''\n",
    "BATCH_SIZE = 64\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18584 images belonging to 10 classes.\n",
      "Found 7956 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input, validation_split=VAL_SPLIT)\n",
    "train_batches = data_gen.flow_from_directory(directory=train_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=BATCH_SIZE, subset=\"training\") \n",
    "valid_batches = data_gen.flow_from_directory(directory=train_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=BATCH_SIZE, subset=\"validation\")\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input).flow_from_directory(directory=test_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "res1 = create_model_ResNet50(number_classes=no_classes, optimizer=optimizer, metrics=metrics)\n",
    "res1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "log_dir=os.path.join('logs','fitres',curTime().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb =  TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch = '500,520')\n",
    "cbks=[tb,es]\n",
    "\n",
    "h_res1 = res1.fit(train_batches,epochs=100, callbacks=cbks,validation_data=valid_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss(f'ResNet50, 128batch, Adamax {augs} - catsv4', h_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res1 = res1.predict(x=test_batches, steps=len(test_batches), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCM(y_true=test_batches.classes, predictions=pred_res1, plot_labels=cm_plot_labels, title=f'Confusion Matrix ResNet50, 128b, Adamax {augs} - catsv4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs='rotation flip brightness'\n",
    "BATCH_SIZE = 64\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18584 images belonging to 10 classes.\n",
      "Found 7956 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(horizontal_flip=True, rotation_range=90,brightness_range=[0.8,1.2], preprocessing_function=tf.keras.applications.resnet.preprocess_input, validation_split=VAL_SPLIT)\n",
    "train_batches = data_gen.flow_from_directory(directory=train_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=BATCH_SIZE, subset=\"training\") \n",
    "valid_batches = data_gen.flow_from_directory(directory=train_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=BATCH_SIZE, subset=\"validation\")\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input).flow_from_directory(directory=test_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "res13 = create_model_ResNet50(number_classes=no_classes, optimizer=optimizer, metrics=metrics)\n",
    "res13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "log_dir=os.path.join('logs','fitres',curTime().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb =  TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch = '500,520')\n",
    "cbks=[tb,es]\n",
    "\n",
    "h_res13 = res13.fit(train_batches,epochs=100, callbacks=cbks,validation_data=valid_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss(f'ResNet50, 128batch, Adamax {augs} - catsv4', h_res13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res13 = res13.predict(x=test_batches, steps=len(test_batches), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCM(y_true=test_batches.classes, predictions=pred_res13, plot_labels=cm_plot_labels, title=f'Confusion Matrix ResNet50, 128b, Adamax {augs} - catsv4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet101\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = ''\n",
    "BATCH_SIZE = 64\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18584 images belonging to 10 classes.\n",
      "Found 7956 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input, validation_split=VAL_SPLIT)\n",
    "train_batches = data_gen.flow_from_directory(directory=train_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=BATCH_SIZE, subset=\"training\") \n",
    "valid_batches = data_gen.flow_from_directory(directory=train_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=BATCH_SIZE, subset=\"validation\")\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input).flow_from_directory(directory=test_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "res2 = create_model_ResNet101(number_classes=no_classes, optimizer=optimizer, metrics=metrics)\n",
    "res2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "log_dir=os.path.join('logs','fitres',curTime().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb =  TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch = '500,520')\n",
    "cbks=[tb,es]\n",
    "\n",
    "h_res2 = res2.fit(train_batches,epochs=100, callbacks=cbks,validation_data=valid_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss(f'ResNet101, 128batch, Adamax {augs} - catsv4', h_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res2 = res2.predict(x=test_batches, steps=len(test_batches), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCM(y_true=test_batches.classes, predictions=pred_res2, plot_labels=cm_plot_labels, title=f'Confusion Matrix ResNet101, 128batch, Adamax {augs} - catsv4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet152\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = ''\n",
    "BATCH_SIZE = 64\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18584 images belonging to 10 classes.\n",
      "Found 7956 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input, validation_split=VAL_SPLIT)\n",
    "train_batches = data_gen.flow_from_directory(directory=train_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=BATCH_SIZE, subset=\"training\") \n",
    "valid_batches = data_gen.flow_from_directory(directory=train_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=BATCH_SIZE, subset=\"validation\")\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet.preprocess_input).flow_from_directory(directory=test_dir, target_size=(INPUT_SIZE,INPUT_SIZE), classes=breeds, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "res3 = create_model_ResNet152(number_classes=no_classes, optimizer=optimizer, metrics=metrics)\n",
    "res3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "log_dir=os.path.join('logs','fitres',curTime().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb =  TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch = '500,520')\n",
    "cbks=[tb,es]\n",
    "\n",
    "h_res3 = res3.fit(train_batches,epochs=100, callbacks=cbks,validation_data=valid_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss(f'ResNet152, 128batch, Adamax {augs} - catsv4', h_res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res3 = res3.predict(x=test_batches, steps=len(test_batches), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCM(y_true=test_batches.classes, predictions=pred_res3, plot_labels=cm_plot_labels, title=f'Confusion Matrix ResNet152, 128b, Adamax {augs} - catsv4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
